{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from the file\n",
    "audio_loaded_model = load('Final_Audio_Model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract more audio features\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {file_path} - {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    if file_path.lower().endswith(\".wav\"):\n",
    "        features = [\n",
    "            np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),\n",
    "            np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
    "            np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),\n",
    "            np.mean(librosa.feature.mfcc(y=y, sr=sr)),\n",
    "            np.mean(librosa.feature.zero_crossing_rate(y)),\n",
    "            np.mean(librosa.feature.spectral_contrast(y=y, sr=sr)),\n",
    "            np.mean(librosa.feature.tempogram(y=y, sr=sr))\n",
    "        ]\n",
    "        return features\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract audio features and labels\n",
    "# Define the root directory where your audio files are stored\n",
    "# Create lists to store features and labels\n",
    "X = []\n",
    "y = []\n",
    "root_dir = \"Audio(OLD)\"\n",
    "for emotion in emotions:\n",
    "    folder_path = os.path.join(root_dir, emotion)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            features = extract_features(file_path)\n",
    "            if features is not None:\n",
    "                X.append(features)\n",
    "                y.append(emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# Convert the feature and label lists to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Encode emotion labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotions:\n",
      "Disgust: 0.71\n",
      "Happy: 0.09\n",
      "Angry: 0.06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_emotions(audio_path, audio_loaded_model, label_encoder):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Extract audio features from the input audio\n",
    "    features = extract_features(audio_path)\n",
    "    if features is not None:\n",
    "        # Standardize the features\n",
    "        features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the emotion probabilities using the loaded model\n",
    "        emotion_probabilities = audio_loaded_model.predict_proba(features)\n",
    "        \n",
    "        # Get the top 3 emotions with highest probabilities\n",
    "        top_emotions_indices = (-emotion_probabilities).argsort()[0][:3]\n",
    "        \n",
    "        top_emotions = label_encoder.inverse_transform(top_emotions_indices)\n",
    "        top_probabilities = [emotion_probabilities[0][index] for index in top_emotions_indices]\n",
    "        \n",
    "        return top_emotions, top_probabilities\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Provide an audio path to predict emotions\n",
    "audio_path = \"RAVDEES_AUDIO\\\\Disgust\\\\03-01-07-01-01-01-04.wav\"\n",
    "predicted_emotions, probabilities = predict_emotions(audio_path, audio_loaded_model, label_encoder)\n",
    "\n",
    "if predicted_emotions is not None:\n",
    "    print(\"Predicted Emotions:\")\n",
    "    for emotion, probability in zip(predicted_emotions, probabilities):\n",
    "        print(f\"{emotion}: {probability:.2f}\")\n",
    "else:\n",
    "    print(\"No emotions predicted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "image_loaded_model = load_model('Final_Image_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class names for your dataset\n",
    "class_names = ['anger', 'disgust', 'fear', 'happy', 'neutral', 'sad']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 244ms/step\n",
      "Predicted Emotion: anger\n",
      "Confidence Scores:\n",
      "anger: 0.48\n",
      "disgust: 0.02\n",
      "fear: 0.43\n",
      "happy: 0.01\n",
      "neutral: 0.05\n",
      "sad: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the input image\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((80, 80))  # Resize the image to the expected dimensions\n",
    "    img = img.convert('RGB')  # Ensure the image has 3 color channels (RGB)\n",
    "    img_array = np.array(img) / 255.0  # Normalize the image data\n",
    "    img_array = img_array.reshape(1, 80, 80, 3)  # Reshape for the model\n",
    "    return img_array\n",
    "\n",
    "# Replace 'input_image.jpg' with the path to your input image\n",
    "input_image_path = 'angry_image.png'\n",
    "\n",
    "# Load and preprocess the input image\n",
    "input_data = load_and_preprocess_image(input_image_path)\n",
    "\n",
    "# Make predictions on the input image\n",
    "predictions = image_loaded_model.predict(input_data)\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "predicted_class = class_names[predicted_class_index]\n",
    "\n",
    "# Print the predicted class and confidence scores\n",
    "print(f'Predicted Emotion: {predicted_class}')\n",
    "print('Confidence Scores:')\n",
    "for i, class_name in enumerate(class_names):\n",
    "    confidence = predictions[0][i]\n",
    "    print(f'{class_name}: {confidence:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "text_loaded_model = joblib.load('Final_Text_Model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the correct encoding for your CSV file\n",
    "encoding = 'ISO-8859-1'  # Replace with the appropriate encoding\n",
    "\n",
    "# Read the CSV file with the specified encoding\n",
    "data = pd.read_csv('Text Data.csv', encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset by emotion\n",
    "happy = data[data['EMOTIONS'] == 'Happy']\n",
    "neutral = data[data['EMOTIONS'] == 'Neutral']\n",
    "sad = data[data['EMOTIONS'] == 'Sad']\n",
    "anger = data[data['EMOTIONS'] == 'Anger']\n",
    "fear = data[data['EMOTIONS'] == 'Fear']\n",
    "disgust = data[data['EMOTIONS'] == 'Disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority classes to match the majority class (Happy)\n",
    "resampled_neutral = resample(neutral, replace=True, n_samples=len(happy), random_state=42)\n",
    "resampled_sad = resample(sad, replace=True, n_samples=len(happy), random_state=42)\n",
    "resampled_anger = resample(anger, replace=True, n_samples=len(happy), random_state=42)\n",
    "resampled_fear = resample(fear, replace=True, n_samples=len(happy), random_state=42)\n",
    "resampled_disgust = resample(disgust, replace=True, n_samples=len(happy), random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the resampled dataframes\n",
    "balanced_data = pd.concat([happy, resampled_neutral, resampled_sad, resampled_anger, resampled_fear, resampled_disgust])\n",
    "\n",
    "# Shuffle the dataset\n",
    "data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into input (X) and target (y)\n",
    "X = data['TEXT'].values\n",
    "y = data['EMOTIONS'].values\n",
    "\n",
    "# Encode emotion labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "max_sequence_length = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disgust: 0.7000\n",
      "Neutral: 0.3000\n",
      "Sad: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded the model using joblib as 'loaded_model'\n",
    "\n",
    "# Example text input\n",
    "new_text = \"Would feel weird swiping right on a leftie\"\n",
    "\n",
    "# Tokenize and pad the new text\n",
    "new_text_seq = tokenizer.texts_to_sequences([new_text])\n",
    "new_text_pad = pad_sequences(new_text_seq, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Make a prediction using the loaded model\n",
    "predicted_probabilities = text_loaded_model.predict_proba(new_text_pad)\n",
    "\n",
    "# Get the top three emotions and their probabilities\n",
    "top_emotions_indices = predicted_probabilities.argsort()[0][-3:][::-1]\n",
    "top_emotions = label_encoder.inverse_transform(top_emotions_indices)\n",
    "top_probabilities = predicted_probabilities[0][top_emotions_indices]\n",
    "\n",
    "# Print the top three predicted emotions and their probabilities\n",
    "for emotion, probability in zip(top_emotions, top_probabilities):\n",
    "    print(f\"{emotion}: {probability:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
